import tensorflow as tf
import numpy as np
# Creating a variable
variable = tf.Variable([1, 2, 3, 4, 5])
print(f"Variable tensor: {variable}")
print(f"Shape: {variable.shape}")  # Shape: (5,)

# Modifying a variable
variable.assign([5, 4, 3, 2, 1])
print(f"Modified variable: {variable}")

# Creating a variable with a specific shape and data type
zeros_var = tf.Variable(tf.zeros([2, 3], dtype=tf.float32))
print(f"Zeros variable: {zeros_var}")
print(f"Shape: {zeros_var.shape}")  # Shape: (2, 3)

# Updating specific elements
zeros_var[0, 1].assign(5.0)
print(f"Updated zeros variable: {zeros_var}")



























import tensorflow as tf
import numpy as np

# Creating a scalar (rank-0 tensor)
scalar = tf.constant(42)
print(f"Scalar tensor: {scalar}")
print(f"Shape: {scalar.shape}")  # Shape: ()

# Creating a vector (rank-1 tensor)
vector = tf.constant([1, 2, 3, 4])
print(f"Vector tensor: {vector}")
print(f"Shape: {vector.shape}")  # Shape: (4,)

# Creating a matrix (rank-2 tensor)
matrix = tf.constant([[1, 2, 3], [4, 5, 6]])
print(f"Matrix tensor: {matrix}")
print(f"Shape: {matrix.shape}")  # Shape: (2, 3)

# Creating a 3D tensor
tensor_3d = tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])
print(f"3D tensor: {tensor_3d}")
print(f"Shape: {tensor_3d.shape}")  # Shape: (2, 2, 2)

# Creating tensors with specific data types
float_tensor = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)
int_tensor = tf.constant([1, 2, 3], dtype=tf.int32)
bool_tensor = tf.constant([True, False, True], dtype=tf.bool)



















































import numpy as np
import tensorflow as tf
# Getting tensor shape info
a = tf.constant([[1, 2, 3], [4, 5, 6]])
print(f"Tensor: {a}")
print(f"Shape: {a.shape}")  # TensorShape([2, 3])
print(f"Rank: {tf.rank(a)}")  # 2
print(f"Size: {tf.size(a)}")  # 6

# Reshaping tensors
reshaped = tf.reshape(a, [3, 2])
print(f"Reshaped tensor: {reshaped}")
print(f"New shape: {reshaped.shape}")  # TensorShape([3, 2])

# Use -1 for automatic dimension calculation
auto_reshape = tf.reshape(a, [1, -1])  # Flattens into a 1Ã—6 tensor
print(f"Auto-reshaped tensor: {auto_reshape}")
print(f"New shape: {auto_reshape.shape}")  # TensorShape([1, 6])

# Expanding dimensions
expanded = tf.expand_dims(a, axis=0)
print(f"Expanded tensor: {expanded}")
print(f"New shape: {expanded.shape}")  # TensorShape([1, 2, 3])


































































import tensorflow as tf
# Broadcasting example
matrix = tf.constant([[1, 2], [3, 4], [5, 6]])  # Shape: (3, 2)
vector = tf.constant([10, 20])                  # Shape: (2,)
result = matrix + vector
print(f"Matrix shape: {matrix.shape}")
print(f"Vector shape: {vector.shape}")
print(f"Result after broadcasting: {result}")
print(f"Result shape: {result.shape}")  # Shape: (3, 2)

# Broadcasting rules demonstration
a = tf.constant([[1, 2, 3]])  # Shape: (1, 3)
b = tf.constant([[4], [5], [6]])  # Shape: (3, 1)
c = a + b  # Broadcasting happens
print(f"Broadcasting result: \n{c}")
print(f"Result shape: {c.shape}")  # Shape: (3, 3)

# Squeezing dimensions (removing dimensions of size 1)
squeezed = tf.squeeze(expanded)
print(f"Squeezed tensor: {squeezed}")
print(f"New shape: {squeezed.shape}")  # Back to TensorShape([2, 3])

# Transposing
transposed = tf.transpose(a)
print(f"Transposed tensor: {transposed}")
print(f"New shape: {transposed.shape}")  # TensorShape([3, 2])



































import tensorflow as tf
import numpy as np
# NumPy array to TensorFlow tensor
numpy_array = np.array([[1, 2, 3], [4, 5, 6]])
tensor_from_np = tf.convert_to_tensor(numpy_array)
print(f"NumPy array: \n{numpy_array}")
print(f"TensorFlow tensor: \n{tensor_from_np}")

# TensorFlow tensor to NumPy array
tensor = tf.constant([[1, 2, 3], [4, 5, 6]])
numpy_from_tf = tensor.numpy()  # or np.array(tensor)
print(f"TensorFlow tensor: \n{tensor}")
print(f"NumPy array: \n{numpy_from_tf}")

# Memory sharing
# Changes to the NumPy array can affect the tensor
numpy_array = np.array([[1, 2, 3], [4, 5, 6]])
tensor = tf.convert_to_tensor(numpy_array)
print(f"Original NumPy array: \n{numpy_array}")
print(f"Original tensor: \n{tensor}")

# Modify the NumPy array
numpy_array[0, 0] = 99
# This won't affect the tensor since tf.convert_to_tensor makes a copy
print(f"Modified NumPy array: \n{numpy_array}")
print(f"Tensor after NumPy modification: \n{tensor}")

# However, tensor.numpy() can share memory with the original tensor in some cases
tensor_var = tf.Variable([[1, 2], [3, 4]])
numpy_view = tensor_var.numpy()
tensor_var.assign([[5, 6], [7, 8]])
print(f"Modified tensor: \n{tensor_var}")
print(f"NumPy view after tensor modification: \n{numpy_view}")  # May or may not reflect changes depending on implementation
